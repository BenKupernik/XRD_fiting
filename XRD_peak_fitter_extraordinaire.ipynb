{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36aca820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import optimize\n",
    "from scipy import integrate\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.integrate import simpson\n",
    "from scipy.integrate import quad\n",
    "from pathlib import Path\n",
    "from os import listdir, chdir\n",
    "from os.path import isfile, join\n",
    "import regex as re\n",
    "from lmfit import Model\n",
    "from lmfit.models import LinearModel, GaussianModel, ExponentialModel, ConstantModel, PowerLawModel, PolynomialModel, LorentzianModel, VoigtModel\n",
    "import math\n",
    "import time\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eaac1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(sample_name, data_path):\n",
    "    \n",
    "    #INPUT - Set the path to the output files from the I vs q script - Use absolute path\n",
    "    #data_path = r'C:\\Users\\Elizabeth\\APS Spring 2022\\Data Processing\\Test_data\\Sample6b_charge_dbl\\Ivsq_text'\n",
    "    #os.chdir(data_path)\n",
    "    \n",
    "    # Importing integrated XRD pattern from APS synchrotron expierment in Fall 2021 at beamline 5-BM-C\n",
    "    file = open(os.path.join(data_path, sample_name))\n",
    "    data = pd.read_csv(file, skiprows = 13, header = None, delim_whitespace=True)\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = ['q','I']\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51e18d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_motor(sample_name, data_path):\n",
    "\n",
    "    try:\n",
    "        # Find the x_motor position in the file title using Regex\n",
    "        start_x = re.search('_x_', sample_name).end()\n",
    "        end_x = re.search('mm_ss_stg2_y_', sample_name).start()\n",
    "        x_motor = sample_name[start_x:end_x].replace(',', '.')\n",
    "        x_motor = float(x_motor)\n",
    "\n",
    "        # Find the y_motor position in the file title using Regex\n",
    "        start_y = re.search('_y_', sample_name).end()\n",
    "        end_y = re.search('mm_primary', sample_name).start()\n",
    "        y_motor = sample_name[start_y:end_y].replace(',', '.')\n",
    "        y_motor = float(y_motor)\n",
    "    \n",
    "    except AttributeError:\n",
    "        print('oh shit bra, the name changed! (function could not find x and y position in file name)')\n",
    "        x_motor = input('Whats the x value?')\n",
    "        x_motor = float(x_motor)\n",
    "        \n",
    "        y_motor = input('Whats the y value?')\n",
    "        y_motor = float(y_motor)\n",
    "        print(\"Groovie.\")\n",
    "    \n",
    "    return x_motor, y_motor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1d80f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(df,q_min,q_max):\n",
    "    \n",
    "    ''' This function creates a condensed dataframe that isolates the deired peak\n",
    "    Inputs: data set in data frame (df), lower q bound for peak(q_min), upper q bound for peak(q_max)\n",
    "    Outputs: shortened dataframe (df_cut)'''\n",
    "    \n",
    "    return df[(df['q'] >= q_min) & (df['q'] <= q_max)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "450a1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(q_max, q_min, model_centers, sig, amp):\n",
    "    background = LinearModel(prefix=('b' + '_'))  \n",
    "    pars = background.make_params()\n",
    "    \n",
    "    model = background\n",
    "    \n",
    "    # initial guesses     \n",
    "    slope1 = 0 \n",
    "    int1 = 12\n",
    "    \n",
    "    # For linear background\n",
    "    pars = background.make_params()\n",
    "    pars['b' + '_slope'].set(slope1)\n",
    "    pars['b' + '_intercept'].set(int1)\n",
    "    \n",
    "    for peak, center in enumerate(model_centers):\n",
    "        # create prefex for each peak\n",
    "        pref = 'g'+str(peak)+'_'\n",
    "        peak = GaussianModel(prefix=pref)\n",
    "        # set the parimiters for each peak\n",
    "        pars.update(peak.make_params())\n",
    "        pars[pref+'center'].set(value=center, min=q_min, max=q_max)\n",
    "        pars[pref+'sigma'].set(value=sig, max = 0.05)\n",
    "        pars[pref+'amplitude'].set(amp, min = 0)\n",
    "        \n",
    "        model = model + peak\n",
    "\n",
    "    return (model, pars)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1fc580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_list(df_cut, q_max, q_min, num_of_centers, num_peaks, sig, amp, peak_name, Li_q_max, Li_q_min):\n",
    "    # set some inital parimiters if its lithium we want to narrow the range it will guess for peaks\n",
    "    if peak_name == 'Li':\n",
    "        temp_max = q_max\n",
    "        temp_min = q_min\n",
    "        q_max = Li_q_max\n",
    "        q_min = Li_q_min\n",
    "    # generate a list of centers to try\n",
    "    increment = (q_max - q_min) / num_of_centers\n",
    "    n = 0\n",
    "    center_list = []\n",
    "    \n",
    "    while n <= num_of_centers:\n",
    "        center_list.append(n*increment + q_min)\n",
    "        n += 1\n",
    "    q_range = q_max - q_min\n",
    "    \n",
    "    if peak_name != 'Li':\n",
    "        center_list[0] = center_list[0] + .1 * q_range\n",
    "        # -1 refers to the last element in the list\n",
    "        center_list[-1] = center_list[-1] - .1 * q_range\n",
    "    \n",
    "    # creat unique combination of peak positions returns a list of tuples. \n",
    "    # Tuples are samp length of num_peaks\n",
    "    center_list = list(it.combinations(center_list, num_peaks))\n",
    "    \n",
    "    # if its lithium we now need to reset the q max/mmin so the model will look at the whole range\n",
    "    if peak_name == 'Li':\n",
    "        q_max = temp_max\n",
    "        q_min = temp_min\n",
    "    \n",
    "    # make a list of models for each center\n",
    "    model_list = []\n",
    "    for center in center_list:\n",
    "        model_list.append(make_model(q_max, q_min, center, sig, amp))\n",
    "    \n",
    "    return(model_list)  \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64bf0c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(df_cut, model, pars):\n",
    "    model_result = model.fit(df_cut['I'], pars, x = df_cut['q'], nan_policy = 'omit')\n",
    "    return(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee65c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_model(best_model, df_cut, sig, amp):\n",
    "    good = 'no'\n",
    "    print(\"\\n\\n fit not found\")\n",
    "    print('The chisqr is ', best_model.chisqr)\n",
    "    best_model.plot()\n",
    "    plt.pause(1)\n",
    "    \n",
    "    good = input('if its good enter yes\\n')\n",
    "    \n",
    "    while good != 'yes':  \n",
    "        try:\n",
    "            centers =  input('Enter peak centers separated by comma \\n')\n",
    "            centers = centers.split(',')\n",
    "            for i in range(len(centers)):\n",
    "                # convert each item to int type\n",
    "                centers[i] = float(centers[i])\n",
    "            print(centers)\n",
    "            # make_model(q_max, q_min, model_centers, sig, amp):\n",
    "            model = make_model(q_max, q_min, centers, sig, amp)\n",
    "            best_model = run_model(df_cut, model[0], model[1])\n",
    "            print(\"chisqr is \", best_model.chisqr)\n",
    "            best_model.plot()\n",
    "            plt.pause(1)\n",
    "            good = input('enter yes to continue. To try again enter no.\\n')\n",
    "        except:\n",
    "            print('operation filed with the following messege')\n",
    "            print('Note for Ben. Add function so this prints error message. Also Hope your science is going well!')\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6566be0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_data(df_cut, q_max, q_min, num_of_centers, sig, amp, chisqu_fit_value, peak_name, Li_q_max, Li_q_min):\n",
    "    chisqr = 1000000000\n",
    "    num_peaks = 1\n",
    "    more_peaks = False\n",
    "    #assign the max number of peaks allowed (1 plus that number so if there can be 3 peaks put 4 here)\n",
    "    if peak_name == 'NMC':\n",
    "        max_peak_allowed = 2\n",
    "    else:\n",
    "        max_peak_allowed = 4\n",
    "    while chisqr >= chisqu_fit_value:\n",
    "\n",
    "        if more_peaks is True and num_peaks >= max_peak_allowed:\n",
    "            #print(\"TURN THE USER FIT BACK ON BEN\")\n",
    "            best_model = user_model(best_model, df_cut, sig, amp)\n",
    "            return best_model\n",
    "        \n",
    "        if num_peaks >= max_peak_allowed:\n",
    "            num_peaks = 1\n",
    "            num_of_centers = num_of_centers*2\n",
    "            more_peaks = True\n",
    "            print(\"THE THING HAPPENED MORE PEAKS\")\n",
    " \n",
    "            \n",
    "        # returns a list of tuples. first value is the model second value is the pars. \n",
    "        # looks like this ((model, pars), (model, pars), ........)\n",
    "        model_list = get_model_list(df_cut, q_max, q_min, num_of_centers, num_peaks, sig, amp, peak_name,\n",
    "                                    Li_q_max, Li_q_min)\n",
    "        \n",
    "        model_result_list = []\n",
    "\n",
    "        for i in range(len(model_list)):\n",
    "            model = model_list[i][0]\n",
    "            pars = model_list[i][1]\n",
    "            model_result_list.append(run_model(df_cut, model, pars))\n",
    "            \n",
    "        results_sorted = sorted(model_result_list, key=lambda model: model.chisqr)\n",
    "        best_model = results_sorted[0]\n",
    "        chisqr = best_model.chisqr\n",
    "        num_peaks += 1\n",
    "        \n",
    "    #best_model.plot()\n",
    "    plt.pause(1)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45578a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(best_model, df_cut):\n",
    "         \n",
    "    # a list of tuples with 4 values. the peak data, fwhm, and center.\n",
    "    # Looks like ((peak_data, fwhm, center, guess), (peak_data, fwhm, center, guess), ........)\n",
    "    comps_list = []\n",
    "    comps = best_model.eval_components(x=df_cut['q'])\n",
    "    for prefex in comps.keys():\n",
    "        if prefex != 'b_':\n",
    "            comps_list.append(((comps[str(prefex)]), best_model.params[str(prefex)+'fwhm'].value, best_model.params[str(prefex)+'center'].value, 1.75))\n",
    "    \n",
    "    \n",
    "    integral_list = []\n",
    "    fwhm_list = []\n",
    "    peak_center_list = []\n",
    "    \n",
    "    for vals in comps_list:\n",
    "        integral_val = integrate_model(df_cut, vals[0], vals[2], vals[3])\n",
    "        integral_list.append(integral_val)\n",
    "        # get_fwhm_center function not needed\n",
    "       # fwhm_list, peak_center_list = get_fwhm_center(integral_val, vals[1], vals[2], vals[3])\n",
    "        fwhm_list.append(vals[1])\n",
    "        peak_center_list.append(vals[2])\n",
    "        \n",
    "    return integral_list, fwhm_list, peak_center_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae27bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_function(read_sample_file, num_of_centers,  data_path, q_min, q_max,  sample_name, sig, amp, chisqu_fit_value, peak_name, Li_q_max, Li_q_min):\n",
    "    \n",
    "    # Make a dataframe of the entire XRD pattern\n",
    "    df = make_dataframe(read_sample_file, data_path)\n",
    "    # Get xy_motor positions\n",
    "    x_motor, y_motor = get_xy_motor(read_sample_file, data_path)\n",
    "    \n",
    "    # Slice the dataframe to desired q range\n",
    "    df_cut = get_points(df, q_min, q_max)\n",
    "\n",
    "    # get the best fit for the data\n",
    "    best_model = fit_data(df_cut, q_max, q_min, num_of_centers, sig, amp, chisqu_fit_value, peak_name, Li_q_max, Li_q_min)\n",
    "\n",
    "    if best_model is not None:\n",
    "        integral_list, fwhm_list, peak_center_list = get_values(best_model, df_cut)\n",
    "    else:\n",
    "        return sample_name, x_motor, y_motor\n",
    "    \n",
    "    return [sample_name, x_motor, y_motor, integral_list, fwhm_list, peak_center_list, best_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb6dc067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_model(df_cut, Gaussian, center_raw, q_guess):\n",
    "    \n",
    "    # Define model\n",
    "    Model = Gaussian\n",
    "    \n",
    "    # Select the data to integrate over\n",
    "    q_range = df_cut['q'].tolist()\n",
    "    \n",
    "\n",
    "    # Caclulate the integral based on the direct data using Simpson's rule\n",
    "    integral = integrate.simpson(Model, q_range, even='avg')\n",
    "    return integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89dcc38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fits(savePath_gen, get_integrals, element, list_of_files, i):\n",
    "    # find the cordanets of the sample and get rid of the dots file paths don't like that\n",
    "    coordinates = (str(get_integrals[1]) + '_' + str(get_integrals[2])).replace('.', '-')\n",
    "    # make it a file path\n",
    "    savePath = os.path.join(savePath_gen, sample_name, element, coordinates)\n",
    "    \n",
    "    # if that foulder dosn't exist make it exist\n",
    "    if not os.path.exists(savePath):\n",
    "\n",
    "        os.makedirs(savePath)\n",
    "\n",
    "    # name the file\n",
    "    y = str(i)\n",
    "    file_name = str(list_of_files[i])\n",
    "    file_name = file_name[:len(file_name) - 5]\n",
    "    fig_path = os.path.join(savePath, file_name)\n",
    "    # save the file! that wasn't at all convaluded was it?\n",
    "    get_integrals[6].plot().savefig(fig_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63586918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding  Graphite-LixC6  peaks! Hold on to your socks!\n",
      "qmax is  1.75 q min is  1.9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "THE THING HAPPENED MORE PEAKS\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "THE THING HAPPENED MORE PEAKS\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "finding  NMC  peaks! Hold on to your socks!\n",
      "qmax is  1.25 q min is  1.36\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "finding  Li  peaks! Hold on to your socks!\n",
      "qmax is  2.49 q min is  2.55\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "Execution time in seconds: 454.77544116973877\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "\n",
    "# Sample info\n",
    "sample_name = 'Sample9_map_charge'\n",
    "\n",
    "# numper of centers to try\n",
    "num_of_centers = 5\n",
    "\n",
    "# the range you want lmift to use for centers for a lithium peak. \n",
    "Li_q_max = 2.52\n",
    "Li_q_min = 2.535\n",
    "\n",
    "#Setup dataframe \n",
    "df_integrals = pd.DataFrame(columns=['Sample', 'file_name', 'x motor', 'y motor',  'Gaussian1', 'FWHM1', 'Center1',\n",
    "                                     'Gaussian2', 'FWHM2', 'Center2', 'Gaussian3', 'FWHM3', 'Center3'])\n",
    "# path to all the tiff files\n",
    "general_folder = r'C:\\Users\\Elizabeth Allan-Cole\\Desktop\\XRD Data Processing\\NSLS-II Winter 2023\\Planning'\n",
    "input_folder = os.path.join(general_folder, 'Ben - test cases', sample_name)\n",
    "output_folder = os.path.join(general_folder,  'intergral_folder',  sample_name)\n",
    "plot_folder = os.path.join(general_folder, 'Plot Output')\n",
    "\n",
    "# if that foulder dosn't exist make it exist\n",
    "if not os.path.exists(output_folder):\n",
    "     os.makedirs(output_folder)\n",
    "\n",
    "#data_path = r\"C:\\Users\\Elizabeth Allan-Cole\\Desktop\\XRD Data Processing\\NSLS-II Winter 2023\\Planning\\Ben - test cases\\Sample9_map_discharge\"\n",
    "\n",
    "# path to whateverfile you want to save pictures of the fits in\n",
    "#plot_folder = 'Plot Output\\\\'\n",
    " #savePath_gen = general_folder + plot_folder + sample_name\n",
    "\n",
    "#Set isolated peak q range dict: [q_min, q_max, chi squared, sigma, amplitude]\n",
    "q_range_dict = {'Graphite-LixC6':[1.75, 1.9, 5, 0.05, 5], 'NMC':[1.25, 1.36, 1000, 0.1, 100], 'Li': [2.49, 2.55, 10, 0.05, 1]}\n",
    "\n",
    "# Graphite/LixC6 only\n",
    "#q_range_dict = {'Graphite-LixC6':[1.75, 1.9, 5, 0.05, 5]}\n",
    "\n",
    "# nmc peaks only\n",
    "#q_range_dict = {'NMC':[1.25, 1.36, 1000, 0.1, 100]}\n",
    "\n",
    "# Li peaks only\n",
    "#q_range_dict = {'Li': [2.49, 2.55, 10, 0.05, 1]}\n",
    "\n",
    "# Make a list of all files names in folder\n",
    "list_of_files = [files for files in listdir(input_folder) if isfile(join(input_folder, files))]\n",
    "\n",
    "\n",
    "for element in q_range_dict.keys():\n",
    "    df_integrals_temp = pd.DataFrame(columns=['Sample', 'file_name', 'x motor', 'y motor',  'Gaussian1', 'FWHM1', 'Center1',\n",
    "                                     'Gaussian2', 'FWHM2', 'Center2', 'Gaussian3', 'FWHM3', 'Center3'])\n",
    "    q_min = q_range_dict.get(element)[0]\n",
    "    q_max = q_range_dict.get(element)[1]\n",
    "    sig = q_range_dict.get(element)[3]\n",
    "    amp =q_range_dict.get(element)[4]\n",
    "    chisqu_fit_value = q_range_dict.get(element)[2]\n",
    "    print(\"finding \", element, \" peaks! Hold on to your socks!\")\n",
    "    print(\"qmax is \" ,q_min, \"q min is \", q_max)\n",
    "\n",
    "    n = 0\n",
    "    # loop through the list of files and append df_integrals --> Troubleshoot the peak fitting, getting weird numbers! \n",
    "    for i in range(len(list_of_files)): \n",
    "        if 'mean_q' in list_of_files[i]:\n",
    "            \n",
    "            #Call the master function to get the integral values for the specified peak\n",
    "            # returns [sample_name, x_motor, y_motor, integral_list, fwhm_list, peak_center_list, best_model]\n",
    "            get_integrals = master_function(list_of_files[i], num_of_centers, input_folder, q_min, q_max, \n",
    "                                            sample_name, sig, amp, chisqu_fit_value, element, Li_q_max, Li_q_min)\n",
    "            \n",
    "            \n",
    "            # save the plots for the best fit if you want\n",
    "            save_fits(plot_folder, get_integrals, element, list_of_files, i)\n",
    "            \n",
    "            \n",
    "            # this just prints the number of files we've cronked through\n",
    "            print(n)\n",
    "            n += 1\n",
    "            \n",
    "            # uncomment me to see the fits!!\n",
    "#             print(get_integrals[6].plot())\n",
    "#             print('chisqr is ', get_integrals[6].chisqr)\n",
    "            \n",
    "            \n",
    "            # zips the integral_list, fwhm_list, peak_center_list together to make a list of lists\n",
    "            # ie ((integral_1, fwhm_1, center_1), (integral_2, fwhm_2, center_2))\n",
    "            vals_list = list(zip(get_integrals[3], get_integrals[4], get_integrals[5]))\n",
    "            \n",
    "            #flatten the list to just a list (integral_1, fwhm_1, center_1, integral_2, fwhm_2, center_2)\n",
    "            vals_list = [item for sublist in vals_list for item in sublist]\n",
    "            \n",
    "            \n",
    "            # add the sample and position info sample_name, x_motor, y_motor\n",
    "            info_list = [get_integrals[0], get_integrals[1], get_integrals[2]]\n",
    "            # add the filename \n",
    "            info_list.insert(1, list_of_files[i])\n",
    "            # add then together\n",
    "            info_list = info_list + vals_list\n",
    "            #Find the number of nan vales we add to make this list have 12 values so we can slap it in a dataframe\n",
    "            num_nans = df_integrals_temp.shape[1] - len(info_list)\n",
    "            \n",
    "            #Add a bunch of nans\n",
    "            x = 0\n",
    "            while x < num_nans:\n",
    "                info_list.append(np.nan)\n",
    "                x += 1\n",
    "                \n",
    "            # find the last row in the df    \n",
    "            max_row = df_integrals_temp.shape[0]\n",
    "            # slap our list of values in the dataframe!\n",
    "            df_integrals_temp.loc[max_row + 1,] = info_list\n",
    "            \n",
    "            \n",
    "    # after each peak is run save the data frame\n",
    "    file_name = str(get_integrals[0] + '_' + element + '.csv')\n",
    "    output_file = os.path.join(output_folder, file_name)\n",
    "    df_integrals_temp.to_csv(output_file)\n",
    "\n",
    "    #add data to the master data frame\n",
    "    if df_integrals.empty:\n",
    "        df_integrals = df_integrals_temp\n",
    "    else:\n",
    "        df_integrals = pd.concat([df_integrals, df_integrals_temp])\n",
    "\n",
    "# save the master dataframe\n",
    "file_name = str(get_integrals[0]) + '_all_data.csv'\n",
    "output_file = os.path.join(output_folder, file_name)\n",
    "df_integrals.to_csv(output_file)\n",
    "\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))# Sample info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "536c60eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IM DONE\n"
     ]
    }
   ],
   "source": [
    "print(\"IM DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00b0335d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sample                                          file_name x motor  \\\n",
      "1    Sample9  Sample9_20220701-141343_907cae_sample_x_30,00m...    30.0   \n",
      "2    Sample9  Sample9_20220701-141343_907cae_sample_x_30,00m...    30.0   \n",
      "3    Sample9  Sample9_20220701-141343_907cae_sample_x_30,00m...    30.0   \n",
      "4    Sample9  Sample9_20220701-141343_907cae_sample_x_30,00m...    30.0   \n",
      "5    Sample9  Sample9_20220701-141343_907cae_sample_x_30,00m...    30.0   \n",
      "..       ...                                                ...     ...   \n",
      "96   Sample9  Sample9_20220701-141343_907cae_sample_x_40,00m...    40.0   \n",
      "97   Sample9  Sample9_20220701-141343_907cae_sample_x_40,00m...    40.0   \n",
      "98   Sample9  Sample9_20220701-141343_907cae_sample_x_40,00m...    40.0   \n",
      "99   Sample9  Sample9_20220701-141343_907cae_sample_x_40,00m...    40.0   \n",
      "100  Sample9  Sample9_20220701-141343_907cae_sample_x_40,00m...    40.0   \n",
      "\n",
      "    y motor Gaussian1     FWHM1   Center1 Gaussian2     FWHM2   Center2  \\\n",
      "1      61.0  0.026099  0.047988  1.875392       NaN       NaN       NaN   \n",
      "2      62.0  0.182504  0.015264   1.85915       NaN       NaN       NaN   \n",
      "3      63.0  0.118016  0.032978  1.854926  0.147973  0.012346  1.856196   \n",
      "4      64.0  0.108171   0.03049  1.850624  0.156209  0.012537  1.853529   \n",
      "5      65.0     0.158  0.117721  1.855129  0.079165  0.016931  1.848805   \n",
      "..      ...       ...       ...       ...       ...       ...       ...   \n",
      "96     66.0  0.003716  0.011804  2.531992       NaN       NaN       NaN   \n",
      "97     67.0  0.003913  0.013109  2.501279       NaN       NaN       NaN   \n",
      "98     68.0  0.051892  0.062068  2.549999       NaN       NaN       NaN   \n",
      "99     69.0  0.002641  0.011915  2.532598       NaN       NaN       NaN   \n",
      "100    70.0  0.001046  0.011885   2.53067       NaN       NaN       NaN   \n",
      "\n",
      "    Gaussian3     FWHM3   Center3  \n",
      "1         NaN       NaN       NaN  \n",
      "2         NaN       NaN       NaN  \n",
      "3         NaN       NaN       NaN  \n",
      "4         NaN       NaN       NaN  \n",
      "5    0.130007  0.020642  1.826724  \n",
      "..        ...       ...       ...  \n",
      "96        NaN       NaN       NaN  \n",
      "97        NaN       NaN       NaN  \n",
      "98        NaN       NaN       NaN  \n",
      "99        NaN       NaN       NaN  \n",
      "100       NaN       NaN       NaN  \n",
      "\n",
      "[300 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print( df_integrals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e323d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
