{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36aca820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import optimize\n",
    "from scipy import integrate\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.integrate import simpson\n",
    "from scipy.integrate import quad\n",
    "from pathlib import Path\n",
    "from os import listdir, chdir\n",
    "from os.path import isfile, join\n",
    "import regex as re\n",
    "from lmfit import Model\n",
    "from lmfit.models import LinearModel, GaussianModel, ExponentialModel, ConstantModel, PowerLawModel, PolynomialModel, LorentzianModel, VoigtModel\n",
    "import math\n",
    "import time\n",
    "import itertools as it\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eaac1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(sample_name, data_path):\n",
    "    \n",
    "    #INPUT - Set the path to the output files from the I vs q script - Use absolute path\n",
    "    #data_path = r'C:\\Users\\Elizabeth\\APS Spring 2022\\Data Processing\\Test_data\\Sample6b_charge_dbl\\Ivsq_text'\n",
    "    os.chdir(data_path)\n",
    "    \n",
    "    # Importing integrated XRD pattern from APS synchrotron expierment in Fall 2021 at beamline 5-BM-C\n",
    "    file = open(sample_name)\n",
    "    data = pd.read_csv(file, skiprows = 13, header = None, delim_whitespace=True)\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = ['q','I']\n",
    "    #display(df)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51e18d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_motor(sample_name, data_path):\n",
    "\n",
    "    try:\n",
    "        # Find the x_motor position in the file title using Regex\n",
    "        start_x = re.search('_x_', sample_name).end()\n",
    "        end_x = re.search('mm_ss_stg2_y_', sample_name).start()\n",
    "        x_motor = sample_name[start_x:end_x].replace(',', '.')\n",
    "        x_motor = float(x_motor)\n",
    "\n",
    "        # Find the y_motor position in the file title using Regex\n",
    "        start_y = re.search('_y_', sample_name).end()\n",
    "        end_y = re.search('mm_primary', sample_name).start()\n",
    "        y_motor = sample_name[start_y:end_y].replace(',', '.')\n",
    "        y_motor = float(y_motor)\n",
    "    \n",
    "    except AttributeError:\n",
    "        print('oh shit bra, the name changed! (function could not find x and y position in file name)')\n",
    "        x_motor = input('Whats the x value?')\n",
    "        x_motor = float(x_motor)\n",
    "        \n",
    "        y_motor = input('Whats the y value?')\n",
    "        y_motor = float(y_motor)\n",
    "        print(\"Groovie.\")\n",
    "    \n",
    "    return x_motor, y_motor\n",
    "\n",
    "#x_motor, y_motor = get_xy_motor(sample_name, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1d80f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(df,q_min,q_max):\n",
    "    \n",
    "    ''' This function creates a condensed dataframe that isolates the deired peak\n",
    "    Inputs: data set in data frame (df), lower q bound for peak(q_min), upper q bound for peak(q_max)\n",
    "    Outputs: shortened dataframe (df_cut)'''\n",
    "    \n",
    "    return df[(df['q'] >= q_min) & (df['q'] <= q_max)]\n",
    "\n",
    "#df_cut = get_points(df,q_min,q_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6adc8b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lmfit_model(df_cut, q1_guess, q2_guess, data_path, x_motor, y_motor, peak_name, plot, sample_name):\n",
    "    x = df_cut['q']\n",
    "    y = df_cut['I']\n",
    "    \n",
    "    b = 'background'\n",
    "    p1 = 'peak1'\n",
    "    p2 = 'peak2'\n",
    "    \n",
    "    #initial guesses     \n",
    "    slope1 = 0 \n",
    "    int1 = 12\n",
    "    \n",
    "    #initial guess conditions for peak 1 \n",
    "    q1 = q1_guess\n",
    "    q1min = q1 - 0.01\n",
    "    q1max = q1 + 0.02 \n",
    "    sig = 0.01\n",
    "    amp = 1\n",
    "    \n",
    "    #initial guess conditions for peak 2 \n",
    "    q2 = q2_guess\n",
    "    q2min = q2 - 0.01\n",
    "    q2max = q2 + 0.02 \n",
    "\n",
    "    background = LinearModel(prefix=(b + '_'))  \n",
    "    pars = background.make_params()\n",
    "    \n",
    "    # For linear background\n",
    "    pars = background.make_params()\n",
    "    pars[b + '_slope'].set(slope1)\n",
    "    pars[b + '_intercept'].set(int1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Gaussian peak 1\n",
    "    peak1 = GaussianModel(prefix= (p1 + '_'))\n",
    "    pars.update(peak1.make_params())\n",
    "    pars[p1+'_center'].set(q1, max = q1max, min = q1min)\n",
    "    pars[p1+'_sigma'].set(sig, max = 0.05)\n",
    "    pars[p1+'_amplitude'].set(amp, min = 0)\n",
    "    \n",
    "    # Gaussian peak 2\n",
    "    peak2 = GaussianModel(prefix= (p2 + '_'))\n",
    "    pars.update(peak2.make_params())\n",
    "    pars[p2+'_center'].set(q2, max = q2max, min = q2min) \n",
    "    pars[p2+'_sigma'].set(sig, max = 0.05)\n",
    "    pars[p2+'_amplitude'].set(amp, min = 0)\n",
    "    \n",
    "    model = peak1 + peak2 + background\n",
    "    \n",
    "    result = model.fit(df_cut['I'], pars, x = df_cut['q'], nan_policy = 'omit')\n",
    "    \n",
    "    comps = result.eval_components(x=x) \n",
    "\n",
    "    #plot 1\n",
    "    if plot == True: \n",
    "        fig, ax = plt.subplots(1,1, figsize=(7,7))\n",
    "        ax.plot(x,y, label='Data')\n",
    "        ax.plot(x,result.best_fit, label='Model')\n",
    "        ax.plot(x, comps[b+'_'], '--', label='Linear')\n",
    "        ax.plot(x, comps[p1+'_'], '--', label='Gaussian1')\n",
    "        ax.plot(x, comps[p2+'_'], '--', label='Gaussian2')\n",
    "\n",
    "        ax.set_xlim(q_min, q_max)\n",
    "        ax.set_title('Graphite, LixC6: ('+ str(x_motor) + ',' + str(y_motor) + ')\\n' + sample_name) \n",
    "        ax.set_xlabel('q [1/A]')\n",
    "        ax.set_ylabel('I [au.]')\n",
    "        ax.legend()\n",
    "    \n",
    "    model = result.best_fit\n",
    "    \n",
    "    # Peak1 fit\n",
    "    Gaussian1 = comps[p1+'_']\n",
    "    fwhm1 = result.params[p1+'_fwhm'].value\n",
    "    center1 = result.params[p1+'_center'].value\n",
    "    \n",
    "    #Peak2 fit\n",
    "    Gaussian2 = comps[p2+'_']\n",
    "    fwhm2 = result.params[p2+'_fwhm'].value\n",
    "    center2 = result.params[p2+'_center'].value\n",
    "    \n",
    "    return Gaussian1, fwhm1, center1, Gaussian2, fwhm2, center2\n",
    "\n",
    "#result = lmfit_model(df_cut, q_min, q_max)\n",
    "#print(result)6y6yy^\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "450a1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(q_max, q_min, model_centers, sig, amp):\n",
    "    background = LinearModel(prefix=('b' + '_'))  \n",
    "    pars = background.make_params()\n",
    "    \n",
    "    model = background\n",
    "    \n",
    "    # initial guesses     \n",
    "    slope1 = 0 \n",
    "    int1 = 12\n",
    "    \n",
    "    # For linear background\n",
    "    pars = background.make_params()\n",
    "    pars['b' + '_slope'].set(slope1)\n",
    "    pars['b' + '_intercept'].set(int1)\n",
    "    \n",
    "    for peak, center in enumerate(model_centers):\n",
    "        # create prefex for each peak\n",
    "        pref = 'g'+str(peak)+'_'\n",
    "        peak = GaussianModel(prefix=pref)\n",
    "        # set the parimiters for each peak\n",
    "        pars.update(peak.make_params())\n",
    "        pars[pref+'center'].set(value=center, min=q_min, max=q_max)\n",
    "        pars[pref+'sigma'].set(value=sig, max = 0.05)\n",
    "        pars[pref+'amplitude'].set(amp, min = 0)\n",
    "        \n",
    "        model = model + peak\n",
    "\n",
    "    return (model, pars)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1fc580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_list(df_cut, q_max, q_min, num_of_centers, num_peaks, sig, amp):\n",
    "    # set some inital parimiters\n",
    "    \n",
    "    # generate a list of centers to try\n",
    "    increment = (q_max - q_min) / num_of_centers\n",
    "    n = 0\n",
    "    center_list = []\n",
    "    \n",
    "    while n <= num_of_centers:\n",
    "        center_list.append(n*increment + q_min)\n",
    "        n += 1\n",
    "    q_range = q_max - q_min\n",
    "    center_list[0] = center_list[0] + .1 * q_range\n",
    "    # -1 refers to the last element in the list\n",
    "    center_list[-1] = center_list[-1] - .1 * q_range\n",
    "    \n",
    "    # creat unique combination of peak positions returns a list of tuples. \n",
    "    # Tuples are samp length of num_peaks\n",
    "    center_list = list(it.combinations(center_list, num_peaks))\n",
    "    \n",
    "    # make a list of models for each center\n",
    "    model_list = []\n",
    "    for center in center_list:\n",
    "        model_list.append(make_model(q_max, q_min, center, sig, amp))\n",
    "    \n",
    "    return(model_list)  \n",
    "        \n",
    "    # result = model.fit(df_cut['I'], pars, x = df_cut['q'], nan_policy = 'omit')\n",
    "    # mod_results = \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e618f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(df_cut, model, pars):\n",
    "    model_result = model.fit(df_cut['I'], pars, x = df_cut['q'], nan_policy = 'omit')\n",
    "    return(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aadb8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_model(best_model, df_cut, sig, amp):\n",
    "    good = 'no'\n",
    "    print(\"\\n\\n fit not found\")\n",
    "    best_model.plot()\n",
    "    plt.pause(1)\n",
    "    while good != 'yes':  \n",
    "        try:\n",
    "            centers =  input('Enter peak centers separated by space \\n')\n",
    "            centers = centers.split(',')\n",
    "            for i in range(len(centers)):\n",
    "                # convert each item to int type\n",
    "                centers[i] = float(centers[i])\n",
    "            print(centers)\n",
    "            # make_model(q_max, q_min, model_centers, sig, amp):\n",
    "            model = make_model(q_max, q_min, centers, sig, amp)\n",
    "            best_model = run_model(df_cut, model[0], model[1])\n",
    "            print(\"chisqr is \", best_model.chisqr)\n",
    "            best_model.plot()\n",
    "            plt.pause(1)\n",
    "            good = input('enter yes to continue. To try again enter no\\n')\n",
    "        except:\n",
    "            print('operation filed with the following messege')\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e539fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_data(df_cut, q_max, q_min, num_of_centers, sig, amp):\n",
    "    chisqr = 10000\n",
    "    num_peaks = 1\n",
    "    while chisqr >= 3:\n",
    "        \n",
    "        if num_peaks >= 4:\n",
    "            print('turn user_model on')\n",
    "            #best_model = user_model(best_model, df_cut, sig, amp)\n",
    "            return best_model\n",
    "            \n",
    "        # returns a list of tuples. first value is the model second value is the pars. \n",
    "        # looks like this ((model, pars), (model, pars), ........)\n",
    "        model_list = get_model_list(df_cut, q_max, q_min, num_of_centers, num_peaks, sig, amp)\n",
    "        \n",
    "        model_result_list = []\n",
    "\n",
    "        for i in range(len(model_list)):\n",
    "            model = model_list[i][0]\n",
    "            pars = model_list[i][1]\n",
    "            model_result_list.append(run_model(df_cut, model, pars))\n",
    "            \n",
    "        results_sorted = sorted(model_result_list, key=lambda model: model.chisqr)\n",
    "        best_model = results_sorted[0]\n",
    "        chisqr = best_model.chisqr\n",
    "        num_peaks += 1\n",
    "        \n",
    "    #best_model.plot()\n",
    "    plt.pause(1)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4989b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(best_model, df_cut):\n",
    "         \n",
    "    # a list of tuples with 4 values. the peak data, fwhm, and center.\n",
    "    # Looks like ((peak_data, fwhm, center, guess), (peak_data, fwhm, center, guess), ........)\n",
    "    comps_list = []\n",
    "    comps = best_model.eval_components(x=df_cut['q'])\n",
    "    for prefex in comps.keys():\n",
    "        if prefex != 'b_':\n",
    "            comps_list.append(((comps[str(prefex)]), best_model.params[str(prefex)+'fwhm'].value, best_model.params[str(prefex)+'center'].value, 1.75))\n",
    "    \n",
    "    \n",
    "    integral_list = []\n",
    "    fwhm_peak_center_list = []\n",
    "    \n",
    "    for vals in comps_list:\n",
    "        integral_val = integrate_model(df_cut, vals[0], vals[2], vals[3])\n",
    "        integral_list.append(integral_val)\n",
    "        fwhm_peak_center_list = get_fwhm_center(integral_val, vals[1], vals[2], vals[3])\n",
    "        \n",
    "    return integral_list, fwhm_peak_center_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae27bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_function(read_sample_file, num_of_centers,  data_path, q_min, q_max, peak_name, sample_name, sig, amp):\n",
    "    \n",
    "    # Make a dataframe of the entire XRD pattern\n",
    "    df = make_dataframe(read_sample_file, data_path)\n",
    "    # Get xy_motor positions\n",
    "    x_motor, y_motor = get_xy_motor(read_sample_file, data_path)\n",
    "    \n",
    "    # Slice the dataframe to desired q range\n",
    "    df_cut = get_points(df, q_min, q_max)\n",
    "\n",
    "    # get the best fit for the data\n",
    "    best_model = fit_data(df_cut, q_max, q_min, num_of_centers, sig, amp)\n",
    "\n",
    "    if best_model is not None:\n",
    "        integral_list, fwhm_peak_center_list = get_values(best_model, df_cut)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    \n",
    "    # Use lmfit to generate peak model\n",
    "    #(Gaussian1, fwhm1_raw, center1_raw, Gaussian2, fwhm2_raw, center2_raw) = lmfit_model(df_cut, \n",
    "    #    q1_guess, q2_guess, data_path, x_motor, y_motor, peak_name, plot, read_sample_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     #Integrate the model numerically \n",
    "#     integral1 = integrate_model(df_cut, Gaussian1, center1_raw, q1_guess)\n",
    "#     integral2 = integrate_model(df_cut, Gaussian2, center2_raw, q2_guess)\n",
    "    \n",
    "#     #Get FWHM and Peak Center\n",
    "#     fwhm1, center1 = get_fwhm_center(integral1, fwhm1_raw, center1_raw, q1_guess)\n",
    "#     fwhm2, center2 = get_fwhm_center(integral2, fwhm2_raw, center2_raw, q2_guess)\n",
    "    \n",
    "    return [sample_name, x_motor, y_motor, integral_list, fwhm_peak_center_list, best_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c65c135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fwhm_center(integral, fwhm_raw, center_raw, q_guess): \n",
    "        \n",
    "    if integral > 0.05 and center_raw < q_guess + 0.05 and center_raw > q_guess - 0.05:\n",
    "        fwhm = fwhm_raw\n",
    "        center = center_raw\n",
    "    else:\n",
    "        fwhm = float(\"nan\") \n",
    "        center = float(\"nan\") \n",
    "    return fwhm, center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0bdd7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_model(df_cut, Gaussian, center_raw, q_guess):\n",
    "    \n",
    "    # Define model\n",
    "    Model = Gaussian\n",
    "    \n",
    "    # Select the data to integrate over\n",
    "    q_range = df_cut['q'].tolist()\n",
    "    \n",
    "\n",
    "    # Caclulate the integral based on the direct data using Simpson's rule\n",
    "    integral = integrate.simpson(Model, q_range, even='avg')\n",
    "    \n",
    "    if integral > 0.05 and center_raw < q_guess + 0.05 and center_raw > q_guess - 0.05:\n",
    "        return integral\n",
    "    else: \n",
    "        integral = float(\"nan\")\n",
    "        return integral\n",
    "\n",
    "#integral = integrate_model3(df_cut, result)\n",
    "#print(integral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63586918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "C:\\Users\\Elizabeth Allan-Cole\\Desktop\\XRD Data Processing\\NSLS-II Winter 2023\\Planning\\test pics\\Sample9\\Model_plots\\30.0\\66.0\\Sample9_20220701-141343_907cae_sample_x_30,00mm_ss_stg2_y_66,00mm_primary-51_mean_q.chi\\.pdf\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Elizabeth Allan-Cole\\\\Desktop\\\\XRD Data Processing\\\\NSLS-II Winter 2023\\\\Planning\\\\test pics\\\\Sample9\\\\Model_plots\\\\30.0\\\\66.0\\\\Sample9_20220701-141343_907cae_sample_x_30,00mm_ss_stg2_y_66,00mm_primary-51_mean_q.chi\\\\.pdf/Sample9_20220701-141343_907cae_sample_x_30,00mm_ss_stg2_y_66,00mm_primary-51_mean_q.chi_graphite_LixC6.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 39>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28mprint\u001b[39m(savePath)\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;66;03m#get_integrals[5].plot().savefig(savePath)\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m         \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[43msavePath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_of_files\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpeak_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;66;03m#Fill in dataframe columns    \u001b[39;00m\n\u001b[0;32m     59\u001b[0m        \u001b[38;5;66;03m# df_integrals.loc[i,] = get_integrals\u001b[39;00m\n\u001b[0;32m     60\u001b[0m         \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# # Turn dataframe into csv file\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# #integral_file = df_integrals.to_csv(integral_folder_path + '\\\\' + sample_name + '_' + peak_name + '.csv' , index=False)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:958\u001b[0m, in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[38;5;241m.\u001b[39msavefig)\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavefig\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    957\u001b[0m     fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[1;32m--> 958\u001b[0m     res \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    959\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()   \u001b[38;5;66;03m# need this if 'transparent=True' to reset colors\u001b[39;00m\n\u001b[0;32m    960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\figure.py:3019\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   3015\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[0;32m   3016\u001b[0m         stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[0;32m   3017\u001b[0m             ax\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39m_cm_set(facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m-> 3019\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(fname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py:2319\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2316\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2317\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2318\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m-> 2319\u001b[0m         result \u001b[38;5;241m=\u001b[39m print_method(\n\u001b[0;32m   2320\u001b[0m             filename,\n\u001b[0;32m   2321\u001b[0m             facecolor\u001b[38;5;241m=\u001b[39mfacecolor,\n\u001b[0;32m   2322\u001b[0m             edgecolor\u001b[38;5;241m=\u001b[39medgecolor,\n\u001b[0;32m   2323\u001b[0m             orientation\u001b[38;5;241m=\u001b[39morientation,\n\u001b[0;32m   2324\u001b[0m             bbox_inches_restore\u001b[38;5;241m=\u001b[39m_bbox_inches_restore,\n\u001b[0;32m   2325\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2326\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py:1648\u001b[0m, in \u001b[0;36m_check_savefig_extra_args.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1640\u001b[0m     _api\u001b[38;5;241m.\u001b[39mwarn_deprecated(\n\u001b[0;32m   1641\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3.3\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39mname, removal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3.6\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1642\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m() got unexpected keyword argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1643\u001b[0m                 \u001b[38;5;241m+\u001b[39m arg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m which is no longer supported as of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1644\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m and will become an error \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1645\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1646\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(arg)\n\u001b[1;32m-> 1648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:386\u001b[0m, in \u001b[0;36mdelete_parameter.<locals>.wrapper\u001b[1;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39minner_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_kwargs):\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inner_args) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m name_idx \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m inner_kwargs:\n\u001b[0;32m    384\u001b[0m         \u001b[38;5;66;03m# Early return in the simple, non-deprecated case (much faster than\u001b[39;00m\n\u001b[0;32m    385\u001b[0m         \u001b[38;5;66;03m# calling bind()).\u001b[39;00m\n\u001b[1;32m--> 386\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39minner_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_kwargs)\n\u001b[0;32m    387\u001b[0m     arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39minner_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_kwargs)\u001b[38;5;241m.\u001b[39marguments\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_varargs \u001b[38;5;129;01mand\u001b[39;00m arguments\u001b[38;5;241m.\u001b[39mget(name):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_pdf.py:2778\u001b[0m, in \u001b[0;36mFigureCanvasPdf.print_pdf\u001b[1;34m(self, filename, dpi, bbox_inches_restore, metadata)\u001b[0m\n\u001b[0;32m   2776\u001b[0m     file \u001b[38;5;241m=\u001b[39m filename\u001b[38;5;241m.\u001b[39m_file\n\u001b[0;32m   2777\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2778\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mPdfFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2779\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2780\u001b[0m     file\u001b[38;5;241m.\u001b[39mnewPage(width, height)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_pdf.py:654\u001b[0m, in \u001b[0;36mPdfFile.__init__\u001b[1;34m(self, filename, metadata)\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_file_like \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtell_base \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 654\u001b[0m fh, opened \u001b[38;5;241m=\u001b[39m \u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_filehandle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_opened\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opened:\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:451\u001b[0m, in \u001b[0;36mto_filehandle\u001b[1;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[0;32m    449\u001b[0m         fh \u001b[38;5;241m=\u001b[39m bz2\u001b[38;5;241m.\u001b[39mBZ2File(fname, flag)\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 451\u001b[0m         fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m     opened \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseek\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Elizabeth Allan-Cole\\\\Desktop\\\\XRD Data Processing\\\\NSLS-II Winter 2023\\\\Planning\\\\test pics\\\\Sample9\\\\Model_plots\\\\30.0\\\\66.0\\\\Sample9_20220701-141343_907cae_sample_x_30,00mm_ss_stg2_y_66,00mm_primary-51_mean_q.chi\\\\.pdf/Sample9_20220701-141343_907cae_sample_x_30,00mm_ss_stg2_y_66,00mm_primary-51_mean_q.chi_graphite_LixC6.pdf'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "startTime = time.time()\n",
    "\n",
    "# Sample info\n",
    "sample_name = 'Sample9'\n",
    "peak_name = 'graphite_LixC6'\n",
    "\n",
    "#Set isolated peak q range\n",
    "q_min = 1.75\n",
    "q_max = 1.9\n",
    "\n",
    "# #Peak loccation guesses\n",
    "# q1_guess = 1.69\n",
    "# q2_guess = 1.87\n",
    "\n",
    "# numper of centers to try\n",
    "num_of_centers = 5\n",
    "\n",
    "#inital guesses for sig and amplatude\n",
    "sig = 0.05 \n",
    "amp = 5\n",
    "\n",
    "#Setup dataframe \n",
    "df_integrals = pd.DataFrame(columns=['Sample','x motor', 'y motor','Gaussian1', 'FWHM1', 'Center1',\n",
    "                                     'Gaussian2', 'FWHM2', 'Center2'])\n",
    "\n",
    "# Set path to correct (where the I vs q data is)\n",
    "# data_path_gen = r'D:\\xpdUser_Allan-Cole_309400_d56e2a5d_2022-07-04-1443\\tiff_base'\n",
    "# data_path = data_path_gen + '\\\\' + sample_name + '\\\\integration'\n",
    "# os.chdir(data_path)\n",
    "\n",
    "data_path = r'C:\\Users\\Elizabeth Allan-Cole\\Desktop\\XRD Data Processing\\NSLS-II Winter 2023\\Planning\\Ben - test cases\\Sample9_map_charge'\n",
    "\n",
    "\n",
    "# Make a list of all files names in folder\n",
    "list_of_files = [files for files in listdir(data_path) if isfile(join(data_path, files))]\n",
    "\n",
    "n = 0\n",
    "# loop through the list of files and append df_integrals --> Troubleshoot the peak fitting, getting weird numbers! \n",
    "for i in range(10,200,2): \n",
    "    if 'mean_q' in list_of_files[i]:\n",
    "        #print(\"\\nnew file start\\n\")\n",
    "        #Call the master function to get the integral values for the specified peak\n",
    "        # returns [sample_name, x_motor, y_motor, integral_list, fwhm_peak_center_list, best_model]\n",
    "        get_integrals = master_function(list_of_files[i], num_of_centers, data_path, q_min, q_max, peak_name, sample_name, sig, amp)\n",
    "        print(n)\n",
    "        n += 1\n",
    "\n",
    "        #Save plot images\n",
    "        savePath_gen = r\"C:\\Users\\Elizabeth Allan-Cole\\Desktop\\XRD Data Processing\\NSLS-II Winter 2023\\Planning\\test pics\"\n",
    "        #os.path.join(path, \"User/Desktop\", \"file.txt\")\n",
    "        savePath = os.path.join(savePath_gen, sample_name, 'Model_plots', str(get_integrals[1]), str(get_integrals[2]), str(list_of_files[i]), \".pdf\")\n",
    "        #savePath = savePath_gen + r'\\' + sample_name + 'Model_plots' + str(get_integrals[1]) + '_' + str(get_integrals[2])\n",
    "        #+ str(list_of_files[i]) + \".pdf\"\n",
    "        print(savePath)\n",
    "        #get_integrals[5].plot().savefig(savePath)\n",
    "        plt.savefig(savePath + '/' + (list_of_files[i] + '_' + peak_name +\".pdf\"))\n",
    "        break\n",
    "        #Fill in dataframe columns    \n",
    "       # df_integrals.loc[i,] = get_integrals\n",
    "        \n",
    "# print(n)    \n",
    "# #Set path to save integral file - Use absolute path - (Where intergral folder will be stored)\n",
    "# integral_folder_path_gen = r'C:\\Users\\Elizabeth Allan-Cole\\Desktop\\XRD Data Processing\\NSLS-II Summer 2022\\Data Processing\\Integral Output'\n",
    "# integral_folder_path = integral_folder_path_gen + '\\\\' + sample_name\n",
    "# os.chdir(integral_folder_path)\n",
    "\n",
    "# # Turn dataframe into csv file\n",
    "# #integral_file = df_integrals.to_csv(integral_folder_path + '\\\\' + sample_name + '_' + peak_name + '.csv' , index=False)\n",
    "\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))# Sample info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a60b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c66474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76237fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    # get number of peaks\n",
    "    # num_peaks = find_peaks(list(df_cut['I']), threshold =.05, prominence = .5)\n",
    "    avg_height = sum(df_cut['I'])/len(df_cut)\n",
    "    num_peaks = find_peaks(list(df_cut['I']), prominence = .3, width = .01, height = avg_height)\n",
    "    print('peaks return value')\n",
    "    print(num_peaks[0])\n",
    "    for x in num_peaks[0]:\n",
    "        print(x, list(df_cut['I'])[x], list(df_cut['q'])[x], avg_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc22953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_function(read_sample_file, num_of_centers,  data_path, q_min, q_max, peak_name, plot, sample_name):\n",
    "    \n",
    "    # Make a dataframe of the entire XRD pattern\n",
    "    df = make_dataframe(read_sample_file, data_path)\n",
    "    # Get xy_motor positions\n",
    "    x_motor, y_motor = get_xy_motor(read_sample_file, data_path)\n",
    "    \n",
    "    # Slice the dataframe to desired q range\n",
    "    df_cut = get_points(df, q_min, q_max)\n",
    "\n",
    "\n",
    "    # TODO loop this till fit is good\n",
    "    chisqr = 10000\n",
    "    num_peaks = 1\n",
    "    while chisqr >= 2:\n",
    "        \n",
    "        if num_peaks >= 4:\n",
    "            print(\"\\n\\n fit not found \\n\\n\")\n",
    "            best_model.plot()\n",
    "            break\n",
    "            \n",
    "        # returns a list of tuples. first value is the model second value is the pars. \n",
    "        # looks like this ((model, pars), (model, pars), ........)\n",
    "        model_list = get_model_list(df_cut, q_max, q_min, num_of_centers, num_peaks, sig = 0.05, amp = 5)\n",
    "        \n",
    "        model_result_list = []\n",
    "\n",
    "        for i in range(len(model_list)):\n",
    "            model = model_list[i][0]\n",
    "            pars = model_list[i][1]\n",
    "            model_result_list.append(run_model(df_cut, model, pars))\n",
    "            \n",
    "        results_sorted = sorted(model_result_list, key=lambda model: model.chisqr)\n",
    "        best_model = results_sorted[0]\n",
    "        chisqr = best_model.chisqr\n",
    "        num_peaks += 1\n",
    "        \n",
    "    best_model.plot()\n",
    "    \n",
    "        \n",
    "        \n",
    "    #TODO add filter to se if fit is good here \n",
    "    # a list of tuples with 4 values. the peak data, fwhm, and center.\n",
    "    # Looks like ((peak_data, fwhm, center, guess), (peak_data, fwhm, center, guess), ........)\n",
    "    comps_list = []\n",
    "    comps = best_model.eval_components(x=df_cut['q'])\n",
    "    for prefex in comps.keys():\n",
    "        if prefex != 'b_':\n",
    "            comps_list.append(((comps[str(prefex)]), best_model.params[str(prefex)+'fwhm'].value, best_model.params[str(prefex)+'center'].value, 1.75))\n",
    "    \n",
    "    \n",
    "    integral_list = []\n",
    "    fwhm_peak_center_list = []\n",
    "    \n",
    "    for vals in comps_list:\n",
    "        integral_val = integrate_model(df_cut, vals[0], vals[2], vals[3])\n",
    "        integral_list.append(integral_val)\n",
    "        fwhm_peak_center_list = get_fwhm_center(integral_val, vals[1], vals[2], vals[3])\n",
    "    \n",
    "    \n",
    "    # Use lmfit to generate peak model\n",
    "    #(Gaussian1, fwhm1_raw, center1_raw, Gaussian2, fwhm2_raw, center2_raw) = lmfit_model(df_cut, \n",
    "    #    q1_guess, q2_guess, data_path, x_motor, y_motor, peak_name, plot, read_sample_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     #Integrate the model numerically \n",
    "#     integral1 = integrate_model(df_cut, Gaussian1, center1_raw, q1_guess)\n",
    "#     integral2 = integrate_model(df_cut, Gaussian2, center2_raw, q2_guess)\n",
    "    \n",
    "#     #Get FWHM and Peak Center\n",
    "#     fwhm1, center1 = get_fwhm_center(integral1, fwhm1_raw, center1_raw, q1_guess)\n",
    "#     fwhm2, center2 = get_fwhm_center(integral2, fwhm2_raw, center2_raw, q2_guess)\n",
    "    \n",
    "    return sample_name, x_motor, y_motor, integral_list, fwhm_peak_center_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
